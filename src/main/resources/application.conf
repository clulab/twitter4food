#
# Configuration file for the classifiers
#

# The file is compartmentalized into multiple classifiers
# and the corresponding local files needed for each

resources = "src/main/resources"

sista_resources = ${resources}/edu/arizona/sista/twitter4food

server_path = "/data/nlp/corpora/twitter4food"

default_package = ${resources}/org/clulab/twitter4food

classifier = ${default_package}/featureclassifier
human = ${classifier}/human
overweight = ${classifier}/overweight
gender = ${classifier}/gender
topics = ${server_path}/topics_tokenized

wordnet = ${server_path}/dict

twitter4j {
  api_keys = ${server_path}/APIKeys.txt
}

oldKeys = ${server_path}/t4fAPIKeys.txt

spam_words = ${default_package}/spam_words.txt

classifiers {
  features {
    stopWords = ${classifier}/features/stopwords.txt
    foodWords = ${sista_resources}/food_words.txt
    hashtags = ${classifier}/features/overweightHashtags.txt
    random_tweets = ${topics}/random_sample_10Oct2013.txt
    overweight_tweets = ${topics}/food_sample_2Oct2013.txt

    followerRelations = ${server_path}/followers/followerRelations.txt
    newFollowerRelations = ${server_path}/followers_tokenized/newFollowerRelations.txt
    followerAccounts = ${server_path}/followers_tokenized/followerAccounts.txt
    newFollowerAccounts = ${server_path}/followers_tokenized/newFollowerAccounts.txt

    #vectors = "/data/nlp/corpora/word2vec/gigaword/vectors.txt"
    vectors = "/data/nlp/corpora/twitter4food/overweight_vectors_clean.txt"
    #vectors = "/data/nlp/corpora/twitter4food/food_vectors_clean.txt"
  }

  overweight {
    data = ${server_path}/overweightData/newTrainData.txt
    data_verbose = ${overweight}/overweight/overweightDataVerbose.txt
    opt_template = ${overweight}/overweight/overweightData_
    midrange = ${classifier}/usersMidrange.txt
    labels = ${overweight}/overweightLabels.txt
    handles = ${overweight}/overweightHandles.txt
    newHandles = ${overweight}/AnnotatedUsers.txt
    annotatedUsersFile = ${overweight}/AnnotatedUsers.txt
    annotatedFoodFile = ${overweight}/food_annotations.txt

    "Overweight" {
      lexicons = [
        ${overweight}/food_words.txt,
        ${overweight}/overweight_hashtags.txt
      ]
    }
    "Not overweight" {
      lexicons = [
        ${overweight}/food_words.txt,
        ${overweight}/overweight_hashtags.txt
      ]
    }

    trainingData = ${server_path}/overweightData_tokenized/overweightTrain.txt
    devData = ${server_path}/overweightData_tokenized/overweightDev.txt
    testData = ${server_path}/overweightData_tokenized/overweightTest.txt

    stream = ${overweight}/overweight_sample_4Apr2016.txt
    opt = ${overweight}/overweightData_

    allTrainData = ${server_path}/newOverweightData/newTrainData.txt
    allTestData = ${overweight}/allTestData.txt

    results = ${overweight}/results
    baseline = "u"
    positiveLabel = "Overweight"

    humanClassifier = ${human}/model/dx.dat
    genderClassifier = ${gender}/models/dux.dat

    followerProp = 1.0

    followeeRelations = ${server_path}/overweightData_tokenized/followeeRelations.txt
    newFolloweeRelations = ${server_path}/overweightData_tokenized/newFolloweeRelations.txt
  }

  human {
    annotatedUsersFile = ${human}/AnnotatedUsers.txt
    opt = ${human}/humanData_
    trainingData = ${server_path}/human_tokenized/trainingData.txt
    devData = ${server_path}/human_tokenized/devData.txt
    testData = ${server_path}/human_tokenized/testData.txt
    model = ${human}/models
    handles = ${human}/AnnotatedUsers.txt

    human {
      lexicons = [
        ${gender}/name_all_lex.txt
        ${human}/human_lexicon.txt
      ]
    }
    org {
      lexicons = [
        ${human}/org_lexicon.txt
      ]
    }

    allTrainData = ${human}/allTrainData.txt
    predictions = ${human}/predictedLabels.txt

    results = ${human}/results
    baseline = "u"

    followeeRelations = ${server_path}/human_tokenized/followeeRelations.txt
  }

  gender {
    annotatedUsersFile = ${gender}/AnnotatedGenders.txt
    trainingFile = ${server_path}/gender_tokenized/trainingSet.txt
    devFile = ${server_path}/gender_tokenized/devSet.txt
    testFile = ${server_path}/gender_tokenized/testSet.txt
    opt = ${gender}/genderData_
    model = ${gender}/models
    handles = ${gender}/AnnotatedGenders.txt

    M {
      lexicons = [
        ${gender}/name_both_first_lex.txt,
        ${gender}/name_both_first_last_lex.txt,
        ${gender}/name_male_first_lex.txt,
        ${gender}/name_male_first_last_lex.txt
      ]
    }
    F {
      lexicons = [
        ${gender}/name_both_first_lex.txt,
        ${gender}/name_both_first_last_lex.txt,
        ${gender}/name_female_first_lex.txt,
        ${gender}/name_female_first_last_lex.txt
      ]
    }

    trainingData = ${server_path}/gender_tokenized/trainingData.txt
    devData = ${server_path}/gender_tokenized/devData.txt
    testData = ${server_path}/gender_tokenized/testData.txt
    allTrainData = ${server_path}/gender_tokenized/allTrainData.txt
    predictions = ${gender}/predictedLabels.txt

    results = ${gender}/results
    baseline = "u"

    followeeRelations = ${server_path}/gender_tokenized/followeeRelations.txt
  }

  race {

  }
}


lda {
  2lineTrainingData = [
    ${classifiers.overweight.trainingData},
    ${classifiers.features.followerAccounts},
    ${classifiers.human.trainingData},
    ${classifiers.gender.trainingData}
  ]
  3lineTrainingData = [
    ${topics}/random_sample_10Oct2013.txt,
    ${topics}/food_sample_2Oct2013.txt
  ]
  stopWords = ${default_package}/lda/stopwords.txt
  modelDir = ${server_path}/lda_models
  topicModel = ${lda.modelDir}/lda_200t_1000i.model
  verbose = true
}
